{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "M1F8EtecU3vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount drive, download PG model from repo, import pretrained weights"
      ],
      "metadata": {
        "id": "xNC4AtDrVDQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mwq4YY_UpBG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Enter the foldername\n",
        "FOLDERNAME = 'cs224n-project'\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "%cd drive/MyDrive\n",
        "%cd $FOLDERNAME\n",
        "%ls .\n",
        "\n",
        "%cd /content/\n",
        "#install disfluency generator and copy over model parameters & weights\n",
        "!git clone https://github.com/SALT-NLP/Disfluency-Generation-and-Detection.git\n",
        "\n",
        "# Need to be in the disf_gen_coarse2fine folder\n",
        "%cd /content/Disfluency-Generation-and-Detection/disf_gen_coarse2fine/\n",
        "\n",
        "%cp /content/drive/MyDrive/cs224n-project/opt.json ./opt.json\n",
        "%cp /content/drive/MyDrive/cs224n-project/m_30.pt ./m_30.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necessary packages"
      ],
      "metadata": {
        "id": "Sarq7vFgVIxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following pip packages need to be installed:\n",
        "!pip install git+https://github.com/huggingface/transformers sentencepiece datasets\n",
        "!pip install torchtext==0.4.0\n",
        "!pip install nltk\n",
        "\n",
        "#Install necessary NLTK packages\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "t4XWHXK9VLQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified PG model functions and helper methods"
      ],
      "metadata": {
        "id": "ZAyBb3qvVPsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helpers\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "import os, sys, re\n",
        "\n",
        "def normalize(raw: str):\n",
        "    return re.sub(r\"[^A-Za-z0-9 ']+\", \"\", raw.lower())\n",
        "\n",
        "def format_disfl_input(dialog):\n",
        "    dialog = normalize(dialog)\n",
        "    tokens = word_tokenize(dialog)\n",
        "    text = \" \".join(tokens)\n",
        "    pos = [pos[1] for pos in pos_tag(tokens)]\n",
        "    o = \" \".join([\"O\"] * len(tokens))\n",
        "\n",
        "    return [text, pos, o]\n",
        "\n",
        "def format_audio_input(disfluency):\n",
        "    text_arr = disfluency.tgt\n",
        "    io_arr = disfluency.tgt_tags\n",
        "    \n",
        "    ret = []\n",
        "    for i, word in enumerate(text_arr):\n",
        "        if io_arr[i] == \"O\":\n",
        "            ret.append(word)\n",
        "            if i<len(text_arr)-1 and io_arr[i+1] == \"I\":\n",
        "                ret.append(\" -- \")\n",
        "        if io_arr[i] == \"I\":\n",
        "            ret.append(word)\n",
        "            if i<len(text_arr)-1 and io_arr[i+1] == \"O\":\n",
        "                ret.append(\" -- \")\n",
        "    return \" \".join(ret)\n",
        "\n",
        "class HiddenPrints:\n",
        "    #https://colab.research.google.com/github/jimit105/pytricks/blob/master/Hide%20print.ipynb\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout"
      ],
      "metadata": {
        "id": "_myEkegjVTHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from table.IO import make_src, make_tgt, merge_vocabs, join_dicts, _dynamic_dict\n",
        "import torchtext\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "UNK_WORD = '<unk>'\n",
        "UNK = 0\n",
        "PAD_WORD = '<pad>'\n",
        "PAD = 1\n",
        "BOS_WORD = '<bos>'\n",
        "BOS = 2\n",
        "EOS_WORD = '<eos>'\n",
        "EOS = 3\n",
        "EOD_WORD = '<eod>'\n",
        "EOD = 4\n",
        "IOD_WORD = '<iod>'\n",
        "IOD = 5\n",
        "\n",
        "BOD_LABEL='E'\n",
        "NBOD_LABEL='N'\n",
        "\n",
        "DISF_LABEL='I'\n",
        "FLT_LABEL='O'\n",
        "\n",
        "def modified_read_anno(reader, opt):\n",
        "    opt.include_flt = True\n",
        "    js_list=[]\n",
        "    num_all=0\n",
        "    i = -1\n",
        "    for line in reader:\n",
        "        i += 1\n",
        "        if i % 4 == 0:\n",
        "            num_all+=1\n",
        "            js_list.append({'sent':[token for token in line.strip().split()]})\n",
        "        elif i % 4 == 1:\n",
        "            continue\n",
        "        if i % 4 == 2:\n",
        "            l = line.strip().split()\n",
        "            assert (len(l) == len(js_list[-1]['sent']))\n",
        "            if not opt.include_flt:\n",
        "                if l==['O']*len(l):\n",
        "                    js_list.pop()\n",
        "                    continue\n",
        "            if l == ['I'] * len(l):\n",
        "                js_list.pop()\n",
        "                continue\n",
        "            assert (len(l)>0)\n",
        "            js_list[-1]['sent_tag']=l\n",
        "        else:\n",
        "            continue\n",
        "    # print(reader, ' all_size:', num_all, ' disf_size:',len(js_list))\n",
        "    if 'gold_diversity' in opt.__dict__ and opt.gold_diversity:\n",
        "        for dic in js_list:\n",
        "            disfs=[]\n",
        "            indisf=0\n",
        "            for i in range(len(dic['sent_tag'])):\n",
        "                if indisf==0 and dic['sent_tag'][i]=='I':\n",
        "                    disfs.append([dic['sent'][i]])\n",
        "                    indisf=1\n",
        "                elif dic['sent_tag'][i]=='I':\n",
        "                    disfs[-1].append(dic['sent'][i])\n",
        "                elif indisf==1 and dic['sent_tag'][i]=='O':\n",
        "                    indisf=0\n",
        "                else:\n",
        "                    pass\n",
        "            dic['disf_frags']=disfs\n",
        "\n",
        "    for dic in js_list:\n",
        "        dic['fsent']=[]\n",
        "        dic['fsent_tag']=[]\n",
        "        for i in range(len(dic['sent_tag'])):\n",
        "            dic['fsent'].append(dic['sent'][i])\n",
        "            dic['fsent_tag'].append(dic['sent_tag'][i])\n",
        "            if dic['sent_tag'][i]=='I' and (i==len(dic['sent_tag'])-1 or dic['sent_tag'][i+1]=='O'):\n",
        "                dic['fsent'].append(EOD_WORD)\n",
        "                dic['fsent_tag'].append('I')\n",
        "        line = []\n",
        "        assert (len(dic['fsent_tag']) > 0)\n",
        "        line.append('E' if dic['fsent_tag'][0] == 'I' else 'N')\n",
        "        for i in range(len(dic['fsent_tag'])):\n",
        "            if dic['fsent_tag'][i] == 'O':\n",
        "                if i < len(dic['fsent_tag']) - 1 and dic['fsent_tag'][i + 1] == 'I':\n",
        "                    line.append('E')\n",
        "                else:\n",
        "                    line.append('N')\n",
        "        dic['src_label']=line\n",
        "        line = []\n",
        "        for w, t in zip(dic['fsent'], dic['fsent_tag']):\n",
        "            if t == 'O':\n",
        "                line.append(w)\n",
        "        dic['src']=line\n",
        "    return js_list\n",
        "\n",
        "def modified_translate_opts(parser, model_path):\n",
        "    parser.add_argument('-root_dir', default='',\n",
        "                        help=\"Path to the root directory.\")\n",
        "    parser.add_argument('-dataset', default='swbd',\n",
        "                        help=\"Name of dataset.\")\n",
        "    parser.add_argument('-tag_type', default='IO',\n",
        "                        help=\"Type of tag system\")\n",
        "    parser.add_argument('-model_path', default=model_path, #required=True,\n",
        "                        help='Path to model .pt file')\n",
        "    parser.add_argument('-split', default=\"test\",\n",
        "                        help=\"Path to the evaluation annotated data\")\n",
        "    #parser.add_argument('-output', default='pred.txt',\n",
        "                        #help=\"\"\"Path to output the predictions (each line will be the decoded sequence\"\"\")\n",
        "    parser.add_argument('-run_from', type=int, default=0,\n",
        "                        help='Only evaluate run.* >= run_from.')\n",
        "    parser.add_argument('-batch_size', type=int, default=1,\n",
        "                        help='Batch size')\n",
        "    parser.add_argument('-beam_size', type=int, default=0,\n",
        "                        help='Beam size')\n",
        "    parser.add_argument('-n_best', type=int, default=1,\n",
        "                        help='N-best size')\n",
        "    '''parser.add_argument('-max_lay_len', type=int, default=50,\n",
        "                        help='Maximum layout decoding length.')\n",
        "    parser.add_argument('-max_tgt_len', type=int, default=100,\n",
        "                        help='Maximum tgt decoding length.')'''\n",
        "    parser.add_argument('-max_disf_len', type=int, default=8,\n",
        "                        help='Maximum layout decoding length.')\n",
        "    parser.add_argument('-gpu', type=str, default='0',\n",
        "                        help=\"Device to run on\")\n",
        "    parser.add_argument('-gold_layout', action='store_true',\n",
        "                        help=\"Given the golden layout sequences for evaluation.\")\n",
        "\n",
        "    parser.add_argument('-random_layout', action='store_true',\n",
        "                        help=\"Use random layout\")\n",
        "\n",
        "    parser.add_argument('-flt_gen', action='store_true',\n",
        "                        help=\"Regenerate fluent part\")\n",
        "\n",
        "    parser.add_argument('-gold_diversity', action='store_true',\n",
        "                        help=\"Report gold diversity\")\n",
        "\n",
        "    parser.add_argument('-no_in_sent_word', action='store_true',\n",
        "                        help=\"no_in_sent_word\")\n",
        "\n",
        "    parser.add_argument('-random_choose_topk', action='store_true',\n",
        "                        help=\"random_choose_topk\")\n",
        "\n",
        "    parser.add_argument('-random_sample', action='store_true',\n",
        "                        help=\"random_sample\")\n",
        "\n",
        "    parser.add_argument('-eval_diversity', action='store_true',\n",
        "                        help=\"evaluate diversity\")\n",
        "\n",
        "    parser.add_argument('-gen_eod', action='store_true',\n",
        "                        help=\"generate eod\")\n",
        "\n",
        "    parser.add_argument('-attn_ignore_small', type=float, default=0,\n",
        "                        help=\"Ignore small attention scores.\")\n",
        "    parser.add_argument('-include_flt', action='store_true', help='include fluent sentences during generation')\n",
        "    parser.add_argument('-sample_num', type=int, default=1,\n",
        "                        help='Number of samples in each step')\n",
        "\n",
        "    parser.add_argument('-translate_num', type=int, default=0,\n",
        "                        help='Number of translation sentences')\n",
        "\n",
        "    parser.add_argument('-queue_size', type=int, default=50,\n",
        "                        help='Number of translation sentences')\n",
        "\n",
        "    parser.add_argument('-temperature', type=float, default=1.0,\n",
        "                        help='temperature of flatting logits')\n",
        "\n",
        "    parser.add_argument('-random_mask_eod', type=float, default=0.0,\n",
        "                        help=\"\"\"During generation, mask EOD with thos prob\"\"\")\n",
        "\n",
        "    parser.add_argument('-output_file', default='pred.txt',\n",
        "                        help=\"\"\"Path to output the predictions and score (each line will be the decoded sequence\"\"\")\n",
        "\n",
        "    parser.add_argument('-master_port', default='12355',\n",
        "                        help=\"\"\"Master Port\"\"\")\n",
        "\n",
        "class ModifiedTableDataset(torchtext.data.Dataset):\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        \"Sort in reverse size order\"\n",
        "        if 'src' in ex.__dict__:\n",
        "            return -len(ex.src)\n",
        "        else:\n",
        "            return -len(ex.sent)\n",
        "\n",
        "    def __init__(self, anno, fields, opt, **kwargs):\n",
        "        \"\"\"\n",
        "        Create a TranslationDataset given paths and fields.\n",
        "        anno: location of annotated data\n",
        "        filter_ex: False - keep all the examples for evaluation (should not have filtered examples); True - filter examples with unmatched spans;\n",
        "        \"\"\"\n",
        "        js_list = anno\n",
        "\n",
        "        self.opt=opt\n",
        "\n",
        "        if opt.disf_seg:\n",
        "            sent_data = self._read_annotated_file(opt, js_list, 'sent')\n",
        "            sent_examples = self._construct_examples(sent_data, 'sent')\n",
        "\n",
        "            sent_tag_data = self._read_annotated_file(opt, js_list, 'sent_tag')\n",
        "            sent_tag_examples = self._construct_examples(sent_tag_data, 'sent_tag')\n",
        "        else:\n",
        "            opt.no_disf_trans=False\n",
        "\n",
        "        if opt.no_disf_trans:\n",
        "            assert (opt.disf_seg)\n",
        "            examples = [join_dicts(*it) for it in\n",
        "                        zip(sent_examples, sent_tag_examples)]\n",
        "                        \n",
        "        else:\n",
        "            src_data = self._read_annotated_file(opt, js_list, 'src')\n",
        "            src_examples = self._construct_examples(src_data, 'src')\n",
        "\n",
        "            assert(opt.disf_seg==False)\n",
        "            examples = [join_dicts(*it) for it in\n",
        "                        zip(src_examples)]\n",
        "\n",
        "        # the examples should not contain None\n",
        "        len_before_filter = len(examples)\n",
        "        examples = list(filter(lambda x: all(\n",
        "            (v is not None for k, v in x.items())), examples))\n",
        "        len_after_filter = len(examples)\n",
        "        num_filter = len_before_filter - len_after_filter\n",
        "        if num_filter > 0:\n",
        "            print('Filter #examples (with None): {} / {} = {:.2%}'.format(num_filter,\n",
        "                                                                          len_before_filter,\n",
        "                                                                  num_filter / len_before_filter))\n",
        "        if not opt.no_disf_trans:\n",
        "            self.src_vocabs = []\n",
        "            for ex_dict in examples:\n",
        "                src_ex_vocab, ex_dict = _dynamic_dict(\n",
        "                    ex_dict)\n",
        "                self.src_vocabs.append(src_ex_vocab)\n",
        "\n",
        "        # Peek at the first to see which fields are used.\n",
        "        ex = examples[0]\n",
        "        keys = ex.keys()\n",
        "        fields = [(k, fields[k])\n",
        "                  for k in (list(keys) + [\"indices\"])]\n",
        "\n",
        "        super(ModifiedTableDataset, self).__init__(\n",
        "            self.construct_final(examples,fields,keys), fields, None)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        # avoid infinite recursion when fields isn't defined\n",
        "        if 'fields' not in vars(self):\n",
        "            raise AttributeError\n",
        "        if attr in self.fields:\n",
        "            return (getattr(x, attr) for x in self.examples)\n",
        "        else:\n",
        "            raise AttributeError\n",
        "\n",
        "    def construct_final(self,examples,fields,keys):\n",
        "        exs=[]\n",
        "        for i, ex in enumerate(examples):\n",
        "            exs.append(torchtext.data.Example.fromlist(\n",
        "                [ex[k] for k in keys] + [i],\n",
        "                fields))\n",
        "        return exs\n",
        "\n",
        "    def filter_pred(self,example):\n",
        "        if self.test:\n",
        "            return True\n",
        "        if not self.opt.no_disf_trans and (len(example.src)>self.opt.src_seq_length or len(example.tgt)>self.opt.tgt_seq_length):\n",
        "            return False\n",
        "        if self.opt.disf_seg and len(example.sent)>self.opt.tgt_seq_length:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def _read_annotated_file(self, opt, js_list, field):\n",
        "        l=[]\n",
        "        if field == 'src':\n",
        "            for dic in js_list:\n",
        "                l.append(dic['src'])\n",
        "            return l\n",
        "        elif field == 'sent':\n",
        "            for dic in js_list:\n",
        "                l.append(dic['sent'])\n",
        "            return l\n",
        "        elif field == 'sent_tag':\n",
        "            for dic in js_list:\n",
        "                l.append([FLT_LABEL]+dic['sent_tag'])\n",
        "            return l\n",
        "        elif field == 'src_label':\n",
        "            for dic in js_list:\n",
        "                l.append(dic['src_label'])\n",
        "            return l\n",
        "        elif field==\"lay_index\":\n",
        "            for dic in js_list:\n",
        "                line = [0]\n",
        "                i=1\n",
        "                for w, t in zip(dic['fsent'], dic['fsent_tag']):\n",
        "                    if t == 'O':\n",
        "                        line.append(i)\n",
        "                        i += 1\n",
        "                    else:\n",
        "                        line.append(0)\n",
        "                l.append(line)\n",
        "            return l\n",
        "        elif field==\"tgt_mask\":\n",
        "            for dic in js_list:\n",
        "                if 'no_connection_decoder' in opt.__dict__ and opt.no_connection_decoder:\n",
        "                    line=[1]+[1]*len(dic['fsent_tag'])\n",
        "                else:\n",
        "                    if 'decoder_word_input' in opt.__dict__ and opt.decoder_word_input:\n",
        "                        line = []\n",
        "                        line.append(0 if dic['fsent_tag'][0] == 'I' else 1)\n",
        "                        for i in range(len(dic['fsent_tag'])):\n",
        "                            if dic['fsent_tag'][i] == 'O' and i < len(dic['fsent_tag']) - 1 and dic['fsent_tag'][\n",
        "                                i + 1] == 'I':\n",
        "                                line.append(0)\n",
        "                            else:\n",
        "                                line.append(1)\n",
        "                    else:\n",
        "                        line = [0] + [1 if t == 'I' else 0 for t in dic['fsent_tag']]\n",
        "                l.append(line)\n",
        "            return l\n",
        "        elif field==\"tgt_loss_mask\":\n",
        "            for dic in js_list:\n",
        "                line = [0 if t=='I' else 1 for t in dic['fsent_tag']] + [1]\n",
        "                l.append(line)\n",
        "            return l\n",
        "        elif field==\"tgt\":\n",
        "            for dic in js_list:\n",
        "                l.append(dic['fsent'])\n",
        "                '''line=[w if t=='I' else PAD_WORD for w, t in zip(dic['fsent'], dic['fsent_tag']) ]\n",
        "                l.append(line)'''\n",
        "            return l\n",
        "        elif field==\"tgt_loss\":\n",
        "            for dic in js_list:\n",
        "                l.append(dic['fsent'])\n",
        "            return l\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "    def _construct_examples(self, lines, side):\n",
        "        l=[]\n",
        "        for words in lines:\n",
        "            example_dict = {side: words}\n",
        "            l.append(example_dict)\n",
        "        return l\n",
        "\n",
        "    def save(self, path, remove_fields=True):\n",
        "        if remove_fields:\n",
        "            self.fields = []\n",
        "        torch.save(self, path)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_fields(vocab):\n",
        "        vocab = dict(vocab)\n",
        "        fields = ModifiedTableDataset.get_fields()\n",
        "        for k, v in vocab.items():\n",
        "            # Hack. Can't pickle defaultdict :(\n",
        "            v.stoi = defaultdict(lambda: 0, v.stoi)\n",
        "            fields[k].vocab = v\n",
        "        return fields\n",
        "\n",
        "    @staticmethod\n",
        "    def save_vocab(fields):\n",
        "        vocab = []\n",
        "        for k, f in fields.items():\n",
        "            if 'vocab' in f.__dict__:\n",
        "                f.vocab.stoi = dict(f.vocab.stoi)\n",
        "                vocab.append((k, f.vocab))\n",
        "        return vocab\n",
        "\n",
        "    @staticmethod\n",
        "    def get_fields(opt=None):\n",
        "        fields = {}\n",
        "        fields[\"sent\"] = torchtext.data.Field(\n",
        "            init_token=IOD_WORD, pad_token=PAD_WORD, include_lengths=True, lower=opt.lower if opt else True)\n",
        "        fields[\"sent_tag\"] = torchtext.data.Field(\n",
        "            pad_token=PAD_WORD, lower=False)\n",
        "        fields[\"src\"] = torchtext.data.Field(\n",
        "            init_token=BOS_WORD,pad_token=PAD_WORD, include_lengths=True,lower=opt.lower if opt else True)\n",
        "        fields[\"src_label\"] = torchtext.data.Field(\n",
        "            pad_token=PAD_WORD, lower=False)\n",
        "        fields[\"lay_index\"] = torchtext.data.Field(\n",
        "            use_vocab=False, pad_token=0)\n",
        "        fields[\"tgt_mask\"] = torchtext.data.Field(\n",
        "            use_vocab=False, dtype=torch.float, pad_token=1)\n",
        "        fields[\"tgt_loss_mask\"] = torchtext.data.Field(\n",
        "            use_vocab=False, dtype=torch.long, pad_token=1)\n",
        "        fields[\"tgt\"] = torchtext.data.Field(\n",
        "            init_token=BOS_WORD, pad_token=PAD_WORD,lower=opt.lower if opt else True)\n",
        "\n",
        "        fields[\"tgt_loss\"] = torchtext.data.Field(\n",
        "            eos_token=EOS_WORD, pad_token=PAD_WORD,lower=opt.lower if opt else True)\n",
        "\n",
        "        fields[\"src_map\"] = torchtext.data.Field(use_vocab=False, dtype=torch.float,\n",
        "            postprocessing=make_src, sequential=False)\n",
        "        fields[\"src_ex_vocab\"] = torchtext.data.RawField()\n",
        "        fields[\"alignment\"] = torchtext.data.Field(use_vocab=False, dtype=torch.long,\n",
        "            postprocessing=make_tgt, sequential=False)\n",
        "        fields[\"indices\"] = torchtext.data.Field(\n",
        "            use_vocab=False, sequential=False)\n",
        "\n",
        "        return fields\n",
        "\n",
        "    @staticmethod\n",
        "    def build_vocab(train, dev, test, opt):\n",
        "        fields = train.fields\n",
        "\n",
        "        if opt.disf_seg:\n",
        "            for field_name in ('sent', 'sent_tag'):\n",
        "                fields[field_name].build_vocab(\n",
        "                    train, min_freq=opt.src_words_min_frequency)\n",
        "\n",
        "        if not opt.no_disf_trans:\n",
        "            src_vocab_all = []\n",
        "            # build vocabulary only based on the training set\n",
        "            # the last one should be the variable 'train'\n",
        "            for split in (dev, test, train,):\n",
        "                fields['src'].build_vocab(split, min_freq=0)\n",
        "                src_vocab_all.extend(list(fields['src'].vocab.stoi.keys()))\n",
        "\n",
        "            # build vocabulary only based on the training set\n",
        "            for field_name in ('src', 'src_label'):\n",
        "                fields[field_name].build_vocab(\n",
        "                    train, min_freq=opt.src_words_min_frequency)\n",
        "            if opt.disf_seg:\n",
        "                src_merge_name_list = ['src', 'sent']\n",
        "                src_merge = merge_vocabs([fields[field_name].vocab for field_name in src_merge_name_list],\n",
        "                                        min_freq=opt.src_words_min_frequency)\n",
        "                for field_name in src_merge_name_list:\n",
        "                    fields[field_name].vocab = src_merge\n",
        "\n",
        "            # build vocabulary only based on the training set\n",
        "            for field_name in ('tgt', 'tgt_loss'):\n",
        "                fields[field_name].build_vocab(\n",
        "                    train, min_freq=opt.tgt_words_min_frequency)\n",
        "\n",
        "            tgt_merge_name_list = ['tgt', 'tgt_loss']\n",
        "            tgt_merge = merge_vocabs([fields[field_name].vocab for field_name in tgt_merge_name_list],\n",
        "                                     min_freq=opt.tgt_words_min_frequency)\n",
        "            for field_name in tgt_merge_name_list:\n",
        "                fields[field_name].vocab = tgt_merge"
      ],
      "metadata": {
        "id": "MkZMBsCCVVoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Models"
      ],
      "metadata": {
        "id": "rmKZASELVehU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create DialoGPT-large model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "dialoGPT_model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "\n",
        "# create TTS model\n",
        "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import soundfile as sf\n",
        "\n",
        "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "tts_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "\n",
        "# load xvector containing speaker's voice characteristics from a dataset\n",
        "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
        "\n",
        "# create disfluency model\n",
        "import torch\n",
        "import table\n",
        "import table.IO\n",
        "import opts\n",
        "import argparse\n",
        "import glob\n",
        "\n",
        "with HiddenPrints():\n",
        "    parser = argparse.ArgumentParser(description='generate.py')\n",
        "    modified_translate_opts(parser, \"m_30.pt\")\n",
        "    opt = parser.parse_args(\"\")\n",
        "    dummy_parser = argparse.ArgumentParser(description='train.py')\n",
        "    opt.dataset = opt.dataset + opt.tag_type\n",
        "    opt.anno = os.path.join(opt.root_dir, opt.dataset, '{}.txt'.format(opt.split))\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if opt.beam_size > 0:\n",
        "        opt.batch_size = 1\n",
        "\n",
        "    opts.model_opts(dummy_parser)\n",
        "    opts.train_opts(dummy_parser)\n",
        "    dummy_opt = dummy_parser.parse_known_args([])[0]\n",
        "\n",
        "    for fn_model in glob.glob(opt.model_path):\n",
        "        opt.model = fn_model\n",
        "        translator = table.Translator(opt, dummy_opt.__dict__)"
      ],
      "metadata": {
        "id": "lu8X3cMjVnLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper methods to call models"
      ],
      "metadata": {
        "id": "WTXZ_VYDVsC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from IPython.display import Audio, display\n",
        "from flask import Response\n",
        "\n",
        "# helpers\n",
        "def generate_disfluency(inp):\n",
        "    js_list = modified_read_anno(inp, opt)\n",
        "\n",
        "    data = ModifiedTableDataset(\n",
        "            js_list, translator.fields, translator.model_opt)\n",
        "    test_data = table.IO.OrderedIterator(\n",
        "                dataset=data, device=device, batch_size=opt.batch_size, train=False, sort=True, sort_within_batch=False)\n",
        "    \n",
        "    # inference\n",
        "    r_list = []\n",
        "    with torch.no_grad():\n",
        "        #print(test_data)\n",
        "        for batch in test_data:\n",
        "            r = translator.translate(batch, js_list)\n",
        "            r_list += r\n",
        "\n",
        "    r_list.sort(key=lambda x: x.idx)\n",
        "    assert len(r_list) == len(js_list), 'len(r_list) != len(js_list): {} != {}'.format(\n",
        "        len(r_list), len(js_list))\n",
        "\n",
        "    pred = r_list[0]\n",
        "    return pred\n",
        "\n",
        "def generate_audio(inp):\n",
        "    inp = TreebankWordDetokenizer().detokenize(inp.split())\n",
        "    inputs = processor(text=inp, return_tensors=\"pt\")\n",
        "    speech = tts_model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
        "    sf.write(\"speech.wav\", speech.numpy(), samplerate=16000)\n",
        "    wn = Audio(\"speech.wav\", autoplay=True) ##\n",
        "    display(wn)"
      ],
      "metadata": {
        "id": "U7FuPEbeVvEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "pUITu6JEV-ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import time\n",
        "from transformers.utils import logging\n",
        "\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "k = 5 # number of lines to chat for\n",
        "\n",
        "for step in range(k):\n",
        "    with HiddenPrints():\n",
        "        new_user_input_ids = tokenizer.encode(input(\">> User: \") + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "        # append the new user input tokens to the chat history\n",
        "        bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "        # generated a response while limiting the total chat history to 1000 tokens, \n",
        "        chat_history_ids = dialoGPT_model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "        disfl_inp = format_disfl_input(response)\n",
        "        disfluency = generate_disfluency(disfl_inp)\n",
        "    if disfluency:\n",
        "        output = TreebankWordDetokenizer().detokenize(disfluency.tgt)\n",
        "        audio_inp = format_audio_input(disfluency)\n",
        "        print(f\">> DialoGPT: {output}\")\n",
        "        generate_audio(audio_inp)\n",
        "        time.sleep(2.5) # let audio load and autoplay"
      ],
      "metadata": {
        "id": "eShyxc-PWAb_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}